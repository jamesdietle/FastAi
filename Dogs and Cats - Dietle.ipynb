{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Everything\n",
    "Make sure we are loading all dependencies and have our custom changes for sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5110)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# Load in theano \n",
    "from theano.sandbox import cuda\n",
    "from imp import reload\n",
    "%matplotlib inline\n",
    "\n",
    "# Loads the utils function\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function\n",
    "\n",
    "#Import images\n",
    "from PIL import Image\n",
    "\n",
    "# Why needed?\n",
    "from utils import plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sets up the pathing\n",
    "path = \"/home/jd/nbs/kdaggledata/\"\n",
    "#path = \"/home/jd/nbs/kdaggledata/sample/\"\n",
    "\n",
    "# Additional Path validtions\n",
    "results_path = path+\"results/\"\n",
    "valid_path = path+\"valid/\"\n",
    "\n",
    "## Set up sound alert\n",
    "from IPython.display import Audio, display\n",
    "from imp import reload\n",
    "import time\n",
    "\n",
    "def allDone():\n",
    "  display(Audio(url='https://sound.peal.io/ps/audios/000/000/537/original/woo_vu_luvub_dub_dub.wav', autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Image Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'vgg16bn' from '/home/jd/FastAi/vgg16bn.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our class, and instantiate\n",
    "from keras import backend as theano\n",
    "import vgg16bn; reload(vgg16bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vgg16 import *\n",
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images and Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As large as you can, but no larger than 64 is recommended. \n",
    "# If you have an older or cheaper GPU, you'll run out of memory, so will have to decrease this.\n",
    "batch_size=32\n",
    "no_of_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24600 images belonging to 2 classes.\n",
      "Found 4920 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = vgg.get_batches(path+'train', batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(valid_path, batch_size=batch_size*4)\n",
    "vgg.finetune(batches)\n",
    "vgg.model.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latest_weights_filename = None\n",
    "for epoch in range(no_of_epochs):\n",
    "    print (\"Running epoch: %d\" % epoch)\n",
    "    vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "    latest_weights_filename = 'ft%d.h5' % epoch\n",
    "    vgg.model.save_weights(results_path+latest_weights_filename)\n",
    "print (\"Completed %s fit operations\" % no_of_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.model.save_weights(path+'results/jd1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.model.load_weights(path+'results/jd1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Messing with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = vgg_ft(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('/home/jd/nbs/kdaggledata/results/jd1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_conv_idx = [index for index,layer in enumerate(layers) \n",
    "                     if type(layer) is Convolution2D][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_conv_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.convolutional.Convolution2D at 0x7f9f57f110b8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[last_conv_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layers = layers[:last_conv_idx+1]\n",
    "conv_model = Sequential(conv_layers)\n",
    "# Dense layers - also known as fully connected or 'FC' layers\n",
    "fc_layers = layers[last_conv_idx+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24600 images belonging to 2 classes.\n",
      "Found 4920 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(path+'train', shuffle=False, batch_size=batch_size)\n",
    "val_batches = get_batches(path+'valid', shuffle=False, batch_size=batch_size)\n",
    "\n",
    "val_classes = val_batches.classes\n",
    "trn_classes = batches.classes\n",
    "val_labels = onehot(val_classes)\n",
    "trn_labels = onehot(trn_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Seems to freeze here\n",
    "val_features = conv_model.predict_generator(val_batches, val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_features = conv_model.predict_generator(batches, batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(results_path + 'train_convlayer_features.bc', trn_features)\n",
    "save_array(results_path + 'valid_convlayer_features.bc', val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_features = load_array(results_path+'train_convlayer_features.bc')\n",
    "val_features = load_array(results_path+'valid_convlayer_features.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24600, 512, 14, 14)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proc_wgts(layer): return [o/2 for o in layer.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = RMSprop(lr=0.00001, rho=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fc_model():\n",
    "    model = Sequential([\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.8),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.8),\n",
    "        Dense(2, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    for l1,l2 in zip(model.layers, fc_layers): l1.set_weights(proc_wgts(l2))\n",
    "\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model = get_fc_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model.fit(trn_features, trn_labels, nb_epoch=8, \n",
    "             batch_size=batch_size, validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model.save_weights(results_path+'jd_no_dropout.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model.load_weights(results_path+'jd_no_dropout.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding in data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator(rotation_range=15, width_shift_range=0.15, \n",
    "                               height_shift_range=0.15, zoom_range=0.15, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24600 images belonging to 2 classes.\n",
      "Found 4920 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# How do I double the amount of files?\n",
    "batches = get_batches(path+'train', gen, batch_size=batch_size)\n",
    "\n",
    "# NB: We don't want to augment or shuffle the validation set\n",
    "val_batches = get_batches(path+'valid', shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model = get_fc_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in conv_model.layers: layer.trainable = False\n",
    "# Look how easy it is to connect two models together!\n",
    "conv_model.add(fc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=2, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=3, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model.save_weights(results_path + 'jdaug3.h5')\n",
    "# jdaug1.h5 is loss .2046 acc .9842 and val_loss .1243 val_acc .9904\n",
    "# jdaug2.h5 is loss .1961 acc .9849 and val_loss .0962 val_acc .9929"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model.load_weights(results_path + 'jdaug1.h5')\n",
    "# jdaug1.h5 is loss .2046 acc .9842 and val_loss .1243 val_acc .9904"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addings batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 14, 14)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layers[-1].output_shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(p),\n",
    "        BatchNormalization(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(p),\n",
    "        BatchNormalization(),\n",
    "        Dense(1000, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model = Sequential(get_bn_layers(0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_2 (Lambda)                (None, 3, 224, 224)   0           lambda_input_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_14 (ZeroPadding2D) (None, 3, 226, 226)   0           lambda_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 64, 224, 224)  1792        zeropadding2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_15 (ZeroPadding2D) (None, 64, 226, 226)  0           convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 64, 224, 224)  36928       zeropadding2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 64, 112, 112)  0           convolution2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_16 (ZeroPadding2D) (None, 64, 114, 114)  0           maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_16 (Convolution2D) (None, 128, 112, 112) 73856       zeropadding2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_17 (ZeroPadding2D) (None, 128, 114, 114) 0           convolution2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_17 (Convolution2D) (None, 128, 112, 112) 147584      zeropadding2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_7 (MaxPooling2D)    (None, 128, 56, 56)   0           convolution2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_18 (ZeroPadding2D) (None, 128, 58, 58)   0           maxpooling2d_7[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_18 (Convolution2D) (None, 256, 56, 56)   295168      zeropadding2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_19 (ZeroPadding2D) (None, 256, 58, 58)   0           convolution2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_19 (Convolution2D) (None, 256, 56, 56)   590080      zeropadding2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_20 (ZeroPadding2D) (None, 256, 58, 58)   0           convolution2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_20 (Convolution2D) (None, 256, 56, 56)   590080      zeropadding2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_8 (MaxPooling2D)    (None, 256, 28, 28)   0           convolution2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_21 (ZeroPadding2D) (None, 256, 30, 30)   0           maxpooling2d_8[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_21 (Convolution2D) (None, 512, 28, 28)   1180160     zeropadding2d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_22 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_22 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_22[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_23 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_22[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_23 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_23[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_9 (MaxPooling2D)    (None, 512, 14, 14)   0           convolution2d_23[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_24 (ZeroPadding2D) (None, 512, 16, 16)   0           maxpooling2d_9[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_24 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_24[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_25 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_24[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_25 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_25[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_26 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_25[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_26 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_26[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_10 (MaxPooling2D)   (None, 512, 7, 7)     0           convolution2d_26[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 25088)         0           maxpooling2d_10[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 4096)          102764544   flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 4096)          0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 4096)          16781312    dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 4096)          0           dense_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 2)             8194        dropout_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 8,194\n",
      "Non-trainable params: 134,260,544\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proc_wgts(layer, prev_p, new_p):\n",
    "    scal = (1-prev_p)/(1-new_p)\n",
    "    return [o*scal for o in layer.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l in bn_model.layers: \n",
    "    if type(l)==Dense: l.set_weights(proc_wgts(l, 0.3, 0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.pop()\n",
    "for layer in bn_model.layers: layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.compile(Adam(), 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24600 samples, validate on 4920 samples\n",
      "Epoch 1/2\n",
      "24600/24600 [==============================] - 8s - loss: 0.2955 - acc: 0.8960 - val_loss: 0.2884 - val_acc: 0.8929\n",
      "Epoch 2/2\n",
      "24600/24600 [==============================] - 8s - loss: 0.3028 - acc: 0.8953 - val_loss: 0.3273 - val_acc: 0.8797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9f5818bfd0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(trn_features, trn_labels, nb_epoch=2, validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bn_model.load_weights('/home/jd/nbs/kdaggledata/results/bn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_layers = get_bn_layers(0.6)\n",
    "bn_layers.pop()\n",
    "bn_layers.append(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model = Sequential(conv_layers)\n",
    "for layer in final_model.layers: layer.trainable = False\n",
    "for layer in bn_layers: final_model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l1,l2 in zip(bn_model.layers, bn_layers):\n",
    "    l2.set_weights(l1.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.compile(optimizer=Adam(), \n",
    "                    loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "24600/24600 [==============================] - 420s - loss: 0.3152 - acc: 0.9432 - val_loss: 0.0786 - val_acc: 0.9768\n",
      "Epoch 2/2\n",
      "24600/24600 [==============================] - 420s - loss: 0.1319 - acc: 0.9584 - val_loss: 0.0595 - val_acc: 0.9827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9c808138d0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=2, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.save_weights(results_path + 'jdfinal1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alldone' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-7472226bdc30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malldone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'alldone' is not defined"
     ]
    }
   ],
   "source": [
    "allDone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=2, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.save_weights(results_path + 'jdfinal1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.load_weights(results_path + 'jdfinal1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.optimizer.lr=0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: [[[[  31.   31.   30. ...,   23.   32.   29.]\n   [  30.   30.   29. ...,   42.  124.   67.]\n   [  29.   29.   28. ...,   75.  117.  190.]\n   ..., \n   [  43.   48.   45. ...,   94.   84.   86.]\n   [  43.   48.   51. ...,  114.  111.  112.]\n   [  29.   34.   41. ...,  120.  123.  118.]]\n\n  [[  13.   13.   12. ...,   22.   83.   52.]\n   [  12.   12.   11. ...,   45.  180.   94.]\n   [  11.   11.   10. ...,   91.  184.  222.]\n   ..., \n   [  82.   84.   79. ...,   94.   82.   79.]\n   [  79.   82.   83. ...,  115.  110.  106.]\n   [  65.   69.   73. ...,  122.  122.  113.]]\n\n  [[   0.    0.    0. ...,   30.  114.   60.]\n   [   0.    0.    0. ...,   60.  215.  103.]\n   [   0.    0.    0. ...,  116.  226.  233.]\n   ..., \n   [  79.   82.   78. ...,   82.   70.   69.]\n   [  77.   81.   82. ...,   99.   92.   90.]\n   [  61.   65.   70. ...,  100.  101.   91.]]]\n\n\n [[[  60.   59.   55. ...,   54.   55.   56.]\n   [  68.   65.   68. ...,   53.   54.   56.]\n   [  63.   60.   58. ...,   54.   54.   56.]\n   ..., \n   [  18.   18.   17. ...,  165.  135.  121.]\n   [  12.   12.   11. ...,  147.   74.   89.]\n   [  12.   11.   10. ...,  119.   49.   66.]]\n\n  [[  56.   59.   57. ...,   59.   57.   54.]\n   [  64.   65.   70. ...,   59.   58.   56.]\n   [  59.   60.   60. ...,   65.   63.   60.]\n   ..., \n   [  14.   14.   13. ...,  167.  134.  118.]\n   [  11.   11.   10. ...,  149.   73.   83.]\n   [  11.   10.    9. ...,  121.   48.   60.]]\n\n  [[  47.   49.   46. ...,   55.   56.   55.]\n   [  55.   55.   59. ...,   55.   57.   56.]\n   [  50.   50.   49. ...,   59.   60.   59.]\n   ..., \n   [  13.   13.   12. ...,  182.  152.  139.]\n   [   7.    7.    6. ...,  174.  105.  109.]\n   [   7.    6.    5. ...,  146.   80.   86.]]]\n\n\n [[[ 165.  119.  188. ...,  149.  198.  187.]\n   [ 168.  107.  176. ...,  171.  191.  202.]\n   [ 174.   95.  163. ...,  186.  177.  193.]\n   ..., \n   [  67.   76.   75. ...,   46.   51.   52.]\n   [  73.   74.   74. ...,   57.   60.   58.]\n   [  78.   73.   73. ...,   63.   68.   69.]]\n\n  [[ 173.  125.  192. ...,  159.  208.  198.]\n   [ 176.  113.  180. ...,  181.  201.  213.]\n   [ 182.  101.  167. ...,  195.  187.  204.]\n   ..., \n   [  64.   73.   72. ...,   43.   48.   49.]\n   [  70.   71.   71. ...,   54.   57.   55.]\n   [  75.   70.   70. ...,   60.   65.   66.]]\n\n  [[ 124.   91.  167. ...,  125.  173.  166.]\n   [ 129.   79.  155. ...,  147.  166.  181.]\n   [ 135.   67.  142. ...,  164.  153.  174.]\n   ..., \n   [  83.   92.   91. ...,   62.   67.   68.]\n   [  89.   90.   90. ...,   73.   76.   74.]\n   [  94.   89.   89. ...,   79.   84.   85.]]]\n\n\n ..., \n [[[  48.   50.   63. ...,   95.   96.   93.]\n   [  49.   51.   63. ...,   94.   94.   91.]\n   [  50.   52.   64. ...,   96.   93.   91.]\n   ..., \n   [ 104.  107.  110. ...,  170.  128.  119.]\n   [ 103.  105.  108. ...,  180.  100.  122.]\n   [ 103.  103.  107. ...,  172.  110.  124.]]\n\n  [[  42.   44.   57. ...,   95.   96.   93.]\n   [  43.   45.   57. ...,   94.   94.   91.]\n   [  44.   46.   58. ...,   96.   93.   91.]\n   ..., \n   [ 102.  105.  108. ...,  168.  132.  128.]\n   [ 101.  103.  106. ...,  178.  104.  131.]\n   [ 101.  101.  105. ...,  170.  114.  133.]]\n\n  [[  44.   46.   59. ...,   97.   98.   95.]\n   [  45.   47.   59. ...,   96.   96.   93.]\n   [  46.   48.   60. ...,   98.   95.   93.]\n   ..., \n   [ 103.  106.  109. ...,  171.  143.  133.]\n   [ 102.  104.  107. ...,  181.  115.  136.]\n   [ 102.  102.  106. ...,  173.  125.  138.]]]\n\n\n [[[  66.   65.   65. ...,    6.    1.    5.]\n   [  63.   63.   63. ...,    6.    5.    9.]\n   [  59.   61.   61. ...,   47.    8.   11.]\n   ..., \n   [ 154.  168.  166. ...,  247.  245.  245.]\n   [ 165.  171.  162. ...,  249.  249.  249.]\n   [ 159.  152.  164. ...,  246.  246.  246.]]\n\n  [[  59.   58.   57. ...,    5.    1.    5.]\n   [  59.   58.   58. ...,    2.    6.   10.]\n   [  59.   61.   60. ...,   41.    9.   12.]\n   ..., \n   [ 124.  138.  136. ...,  249.  247.  247.]\n   [ 135.  141.  132. ...,  251.  251.  251.]\n   [ 129.  122.  134. ...,  248.  248.  248.]]\n\n  [[  51.   52.   54. ...,    3.    0.    3.]\n   [  50.   52.   54. ...,    1.    1.    5.]\n   [  49.   53.   56. ...,   41.    3.    6.]\n   ..., \n   [  90.  104.  102. ...,  246.  246.  246.]\n   [ 101.  107.   98. ...,  248.  250.  250.]\n   [  95.   88.  100. ...,  245.  247.  247.]]]\n\n\n [[[ 229.  227.  230. ...,  134.  116.  122.]\n   [ 226.  224.  227. ...,  165.  166.  171.]\n   [ 227.  226.  229. ...,  117.  111.  116.]\n   ..., \n   [ 184.  185.  181. ...,  202.  198.  188.]\n   [ 169.  165.  151. ...,  197.  195.  189.]\n   [ 155.  138.  111. ...,  207.  210.  203.]]\n\n  [[ 215.  213.  216. ...,   97.   79.   85.]\n   [ 212.  210.  213. ...,  134.  135.  140.]\n   [ 213.  212.  215. ...,   94.   88.   93.]\n   ..., \n   [ 169.  170.  166. ...,  178.  174.  164.]\n   [ 152.  148.  134. ...,  173.  171.  165.]\n   [ 138.  121.   94. ...,  183.  186.  179.]]\n\n  [[ 178.  176.  179. ...,   70.   52.   58.]\n   [ 175.  173.  176. ...,  105.  106.  111.]\n   [ 176.  175.  178. ...,   62.   56.   61.]\n   ..., \n   [ 126.  127.  123. ...,  144.  140.  130.]\n   [ 109.  105.   91. ...,  139.  137.  131.]\n   [  95.   78.   51. ...,  149.  152.  145.]]]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-5bc76fefc655>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m final_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=3, \n\u001b[0;32m----> 2\u001b[0;31m                         validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n\u001b[0m",
      "\u001b[0;32m/home/jd/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[0;32m/home/jd/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1540\u001b[0m                                          \u001b[0;34m'(x, y, sample_weight) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m                                          \u001b[0;34m'or (x, y). Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1542\u001b[0;31m                                          str(generator_output))\n\u001b[0m\u001b[1;32m   1543\u001b[0m                     \u001b[0;31m# build batch logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m                     \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: [[[[  31.   31.   30. ...,   23.   32.   29.]\n   [  30.   30.   29. ...,   42.  124.   67.]\n   [  29.   29.   28. ...,   75.  117.  190.]\n   ..., \n   [  43.   48.   45. ...,   94.   84.   86.]\n   [  43.   48.   51. ...,  114.  111.  112.]\n   [  29.   34.   41. ...,  120.  123.  118.]]\n\n  [[  13.   13.   12. ...,   22.   83.   52.]\n   [  12.   12.   11. ...,   45.  180.   94.]\n   [  11.   11.   10. ...,   91.  184.  222.]\n   ..., \n   [  82.   84.   79. ...,   94.   82.   79.]\n   [  79.   82.   83. ...,  115.  110.  106.]\n   [  65.   69.   73. ...,  122.  122.  113.]]\n\n  [[   0.    0.    0. ...,   30.  114.   60.]\n   [   0.    0.    0. ...,   60.  215.  103.]\n   [   0.    0.    0. ...,  116.  226.  233.]\n   ..., \n   [  79.   82.   78. ...,   82.   70.   69.]\n   [  77.   81.   82. ...,   99.   92.   90.]\n   [  61.   65.   70. ...,  100.  101.   91.]]]\n\n\n [[[  60.   59.   55. ...,   54.   55.   56.]\n   [  68.   65.   68. ...,   53.   54.   56.]\n   [  63.   60.   58. ...,   54.   54.   56.]\n   ..., \n   [  18.   18.   17. ...,  165.  135.  121.]\n   [  12.   12.   11. ...,  147.   74.   89.]\n   [  12.   11.   10. ...,  119.   49.   66.]]\n\n  [[  56.   59.   57. ...,   59.   57.   54.]\n   [  64.   65.   70. ...,   59.   58.   56.]\n   [  59.   60.   60. ...,   65.   63.   60.]\n   ..., \n   [  14.   14.   13. ...,  167.  134.  118.]\n   [  11.   11.   10. ...,  149.   73.   83.]\n   [  11.   10.    9. ...,  121.   48.   60.]]\n\n  [[  47.   49.   46. ...,   55.   56.   55.]\n   [  55.   55.   59. ...,   55.   57.   56.]\n   [  50.   50.   49. ...,   59.   60.   59.]\n   ..., \n   [  13.   13.   12. ...,  182.  152.  139.]\n   [   7.    7.    6. ...,  174.  105.  109.]\n   [   7.    6.    5. ...,  146.   80.   86.]]]\n\n\n [[[ 165.  119.  188. ...,  149.  198.  187.]\n   [ 168.  107.  176. ...,  171.  191.  202.]\n   [ 174.   95.  163. ...,  186.  177.  193.]\n   ..., \n   [  67.   76.   75. ...,   46.   51.   52.]\n   [  73.   74.   74. ...,   57.   60.   58.]\n   [  78.   73.   73. ...,   63.   68.   69.]]\n\n  [[ 173.  125.  192. ...,  159.  208.  198.]\n   [ 176.  113.  180. ...,  181.  201.  213.]\n   [ 182.  101.  167. ...,  195.  187.  204.]\n   ..., \n   [  64.   73.   72. ...,   43.   48.   49.]\n   [  70.   71.   71. ...,   54.   57.   55.]\n   [  75.   70.   70. ...,   60.   65.   66.]]\n\n  [[ 124.   91.  167. ...,  125.  173.  166.]\n   [ 129.   79.  155. ...,  147.  166.  181.]\n   [ 135.   67.  142. ...,  164.  153.  174.]\n   ..., \n   [  83.   92.   91. ...,   62.   67.   68.]\n   [  89.   90.   90. ...,   73.   76.   74.]\n   [  94.   89.   89. ...,   79.   84.   85.]]]\n\n\n ..., \n [[[  48.   50.   63. ...,   95.   96.   93.]\n   [  49.   51.   63. ...,   94.   94.   91.]\n   [  50.   52.   64. ...,   96.   93.   91.]\n   ..., \n   [ 104.  107.  110. ...,  170.  128.  119.]\n   [ 103.  105.  108. ...,  180.  100.  122.]\n   [ 103.  103.  107. ...,  172.  110.  124.]]\n\n  [[  42.   44.   57. ...,   95.   96.   93.]\n   [  43.   45.   57. ...,   94.   94.   91.]\n   [  44.   46.   58. ...,   96.   93.   91.]\n   ..., \n   [ 102.  105.  108. ...,  168.  132.  128.]\n   [ 101.  103.  106. ...,  178.  104.  131.]\n   [ 101.  101.  105. ...,  170.  114.  133.]]\n\n  [[  44.   46.   59. ...,   97.   98.   95.]\n   [  45.   47.   59. ...,   96.   96.   93.]\n   [  46.   48.   60. ...,   98.   95.   93.]\n   ..., \n   [ 103.  106.  109. ...,  171.  143.  133.]\n   [ 102.  104.  107. ...,  181.  115.  136.]\n   [ 102.  102.  106. ...,  173.  125.  138.]]]\n\n\n [[[  66.   65.   65. ...,    6.    1.    5.]\n   [  63.   63.   63. ...,    6.    5.    9.]\n   [  59.   61.   61. ...,   47.    8.   11.]\n   ..., \n   [ 154.  168.  166. ...,  247.  245.  245.]\n   [ 165.  171.  162. ...,  249.  249.  249.]\n   [ 159.  152.  164. ...,  246.  246.  246.]]\n\n  [[  59.   58.   57. ...,    5.    1.    5.]\n   [  59.   58.   58. ...,    2.    6.   10.]\n   [  59.   61.   60. ...,   41.    9.   12.]\n   ..., \n   [ 124.  138.  136. ...,  249.  247.  247.]\n   [ 135.  141.  132. ...,  251.  251.  251.]\n   [ 129.  122.  134. ...,  248.  248.  248.]]\n\n  [[  51.   52.   54. ...,    3.    0.    3.]\n   [  50.   52.   54. ...,    1.    1.    5.]\n   [  49.   53.   56. ...,   41.    3.    6.]\n   ..., \n   [  90.  104.  102. ...,  246.  246.  246.]\n   [ 101.  107.   98. ...,  248.  250.  250.]\n   [  95.   88.  100. ...,  245.  247.  247.]]]\n\n\n [[[ 229.  227.  230. ...,  134.  116.  122.]\n   [ 226.  224.  227. ...,  165.  166.  171.]\n   [ 227.  226.  229. ...,  117.  111.  116.]\n   ..., \n   [ 184.  185.  181. ...,  202.  198.  188.]\n   [ 169.  165.  151. ...,  197.  195.  189.]\n   [ 155.  138.  111. ...,  207.  210.  203.]]\n\n  [[ 215.  213.  216. ...,   97.   79.   85.]\n   [ 212.  210.  213. ...,  134.  135.  140.]\n   [ 213.  212.  215. ...,   94.   88.   93.]\n   ..., \n   [ 169.  170.  166. ...,  178.  174.  164.]\n   [ 152.  148.  134. ...,  173.  171.  165.]\n   [ 138.  121.   94. ...,  183.  186.  179.]]\n\n  [[ 178.  176.  179. ...,   70.   52.   58.]\n   [ 175.  173.  176. ...,  105.  106.  111.]\n   [ 176.  175.  178. ...,   62.   56.   61.]\n   ..., \n   [ 126.  127.  123. ...,  144.  140.  130.]\n   [ 109.  105.   91. ...,  139.  137.  131.]\n   [  95.   78.   51. ...,  149.  152.  145.]]]]"
     ]
    }
   ],
   "source": [
    "final_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=3, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(results_path + 'jdaugbn1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"https://sound.peal.io/ps/audios/000/000/537/original/woo_vu_luvub_dub_dub.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "allDone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "#Ensure that you have a testset fed into batches and preds\n",
    "batches, preds = vgg.test(path+'test', batch_size = batch_size*2)\n",
    "filenames = batches.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test/7807.jpg',\n",
       " 'test/6818.jpg',\n",
       " 'test/8924.jpg',\n",
       " 'test/5985.jpg',\n",
       " 'test/5468.jpg']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test that you can get the predictions AND the files\n",
    "preds[:5]\n",
    "filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save arrays with both predictions and filenames\n",
    "save_array(path+'results/' + 'test_preds.dat', preds)\n",
    "save_array(path+'results/' + 'filenames.dat', filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load both arrays into variables\n",
    "preds= load_array(path+'results/' + 'test_preds.dat')\n",
    "filenames = load_array(path+'results/' + 'filenames.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ids = np.array([int(f[(f.find('.')):(f.find('.jpg'))]) for f in filenames])\n",
    "ids = (np.array(f for f in filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "isdog= preds[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7807, 6818, 8924, 5985, 5468])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the np.array cuts the filenames down to just numbers\n",
    "ids = np.array([int(f[(f.find('/')+1):f.find('.jpg')]) for f in filenames])\n",
    "#Test\n",
    "ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.8070e+03,   2.0000e-02],\n",
       "       [  6.8180e+03,   4.8200e-01],\n",
       "       [  8.9240e+03,   6.2407e-01],\n",
       "       [  5.9850e+03,   1.1234e-01],\n",
       "       [  5.4680e+03,   8.8253e-01]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isadog= isdog\n",
    "for n,i in enumerate(isadog):\n",
    "    if .999<i:\n",
    "        isadog[n]=.999\n",
    "    elif .02>i:\n",
    "        isadog[n]=.001\n",
    "    else:\n",
    "        isadog[n]=i\n",
    "subm = np.stack([ids,isadog], axis=1)\n",
    "#Test\n",
    "subm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Predictions: [ 0.02    0.482   0.6241  0.1123  0.8825]\n",
      "Mid Predictions: 1515\n",
      "Edge Predictions: []\n"
     ]
    }
   ],
   "source": [
    "print (\"Raw Predictions: \" + str(isadog[:5]))\n",
    "print (\"Mid Predictions: \" + str(len(isadog[(isdog < .6) & (isdog > .4)])))\n",
    "print (\"Edge Predictions: \" + str(isadog[(isdog == 1) | (isdog == 0)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission File Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_file_name = 'JD5.csv'\n",
    "np.savetxt(submission_file_name, subm, fmt='%d,%.5f', header='id,label', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='JD5.csv' target='_blank'>JD5.csv</a><br>"
      ],
      "text/plain": [
       "/home/jd/FastAi/JD5.csv"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(submission_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allDone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### wrongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
