{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda\n",
    "cuda.use('gpu0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imp import reload\n",
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use PoC or GTFO, because reasons\n",
    "https://www.alchemistowl.org/pocorgtfo/\n",
    "\n",
    "I did have to make a local file so it could be a text document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Data for the text is pulled locally\n",
    "/home/jd/aidata/pocgtfo.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 1067271\n"
     ]
    }
   ],
   "source": [
    "# Pulls in a file to learn from\n",
    "path = get_file('pocgtfo.txt', origin=\"file:///home/jd/aidata/pocgtfo.txt\")\n",
    "text = open(path).read()\n",
    "\n",
    "# Adds the others. I could make this a loop but im lazy today\n",
    "path2 = get_file('pocgtfo2.txt', origin=\"file:///home/jd/aidata/pocgtfo2.txt\")\n",
    "text2 = open(path2).read()\n",
    "\n",
    "path3 = get_file('pocgtfo3.txt', origin=\"file:///home/jd/aidata/pocgtfo3.txt\")\n",
    "text3 = open(path3).read()\n",
    "\n",
    "path4 = get_file('pocgtfo4.txt', origin=\"file:///home/jd/aidata/pocgtfo4.txt\")\n",
    "text4 = open(path4).read()\n",
    "\n",
    "path5 = get_file('pocgtfo5.txt', origin=\"file:///home/jd/aidata/pocgtfo5.txt\")\n",
    "text5 = open(path5).read()\n",
    "\n",
    "path6 = get_file('pocgtfo6.txt', origin=\"file:///home/jd/aidata/pocgtfo6.txt\")\n",
    "text6 = open(path6).read()\n",
    "\n",
    "path7 = get_file('pocgtfo7.txt', origin=\"file:///home/jd/aidata/pocgtfo7.txt\")\n",
    "text7 = open(path7).read()\n",
    "\n",
    "path8 = get_file('pocgtfo8.txt', origin=\"file:///home/jd/aidata/pocgtfo8.txt\")\n",
    "text8 = open(path8).read()\n",
    "\n",
    "path9 = get_file('pocgtfo9.txt', origin=\"file:///home/jd/aidata/pocgtfo9.txt\")\n",
    "text9 = open(path9).read()\n",
    "\n",
    "path10 = get_file('pocgtfo10.txt', origin=\"file:///home/jd/aidata/pocgtfo10.txt\")\n",
    "text10 = open(path10).read()\n",
    "\n",
    "text = text+text2+text3+text4+text5+text6+text7+text8+text9+text10\n",
    "print('corpus length:', len(text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 202\n"
     ]
    }
   ],
   "source": [
    "# gets the total number of characters fond in the document\n",
    "# There are many unique chars because of the Russian and coding.\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Places in the 0 chars for padding\n",
    "chars.insert(0, \"\\0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n !\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\\x80\\x81\\x82¢£¨«´µ·»ÆÈÉ×àáãéïóõıőˆ˙˜αβγζθλπωϕАБВГДЕЗИЙКЛМНОПРСТУФХЦЧШЫЭЯавдезиклмнорстшё–—‘’“”•→∀∆∈−∗√≡≤⊕␣\\uf731\\uf734'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is the list of chars\n",
    "# Check out how weird they are\n",
    "''.join(chars[1:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates the chars to indicies and back. Lets us make arrays of numbers not chars\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the idx holds the text\n",
    "idx = [char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[43, 80, 86, 71, 84, 80, 67, 86, 75, 81]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'International Journal of PoC k GTFO\\nIssue 0x00, a CFP with PoC\\nAn epistle from the desk of Rt. Revd. Pastor Manul Laphroaig\\npastor@phrack.org\\nAugust 5, 2013\\nLegal Note: Permission to use all or part o'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If everything is working correctly we will have the first sentance of the document\n",
    "''.join(indices_char[i] for i in idx[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data appears to have been properly loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 Char Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make inputs; However we are doing 4 not 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How many chars are we doing\n",
    "cs=4\n",
    "#For the first char... pull back the length -1. Starts chopping up the sentances\n",
    "c1_dat = [idx[i] for i in range(0, len(idx)-1-cs, cs)]\n",
    "c2_dat = [idx[i+1] for i in range(0, len(idx)-1-cs, cs)]\n",
    "c3_dat = [idx[i+2] for i in range(0, len(idx)-1-cs, cs)]\n",
    "c4_dat = [idx[i+3] for i in range(0, len(idx)-1-cs, cs)]\n",
    "c5_dat = [idx[i+3] for i in range(0, len(idx)-1-cs, cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our Input \n",
    "x1 = np.stack(c1_dat[:-2])\n",
    "x2 = np.stack(c2_dat[:-2])\n",
    "x3 = np.stack(c3_dat[:-2])\n",
    "x4 = np.stack(c4_dat[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# our output\n",
    "y = np.stack(c5_dat[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([43, 84, 75, 78]),\n",
       " array([80, 80, 81,  2]),\n",
       " array([86, 67, 80, 44]),\n",
       " array([71, 86, 67, 81]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[:4], x2[:4], x3[:4], x4[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([71, 86, 67, 81])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((266815,), (266815,))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Latent Factors\n",
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_input(name, n_in, n_out):\n",
    "    inp = Input(shape=(1,), dtype='int64', name=name)\n",
    "    emb = Embedding(n_in, n_out, input_length=1)(inp)\n",
    "    return inp, Flatten()(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1_in, c1 = embedding_input('c1', vocab_size, n_fac)\n",
    "c2_in, c2 = embedding_input('c2', vocab_size, n_fac)\n",
    "c3_in, c3 = embedding_input('c3', vocab_size, n_fac)\n",
    "c4_in, c4 = embedding_input('c4', vocab_size, n_fac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train model\n",
    "Pick a size for hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creates the first arrow in from the model\n",
    "dense_in = Dense(n_hidden, activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the hidden activation\n",
    "c1_hidden = dense_in(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Orange arrows\n",
    "dense_hidden = Dense(n_hidden, activation='tanh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other hidden activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c2_dense = dense_in(c2)\n",
    "hidden_2 = dense_hidden(c1_hidden)\n",
    "c2_hidden = merge([c2_dense, hidden_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c3_dense = dense_in(c3)\n",
    "hidden_3 = dense_hidden(c2_hidden)\n",
    "c3_hidden = merge([c3_dense, hidden_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c4_dense = dense_in(c4)\n",
    "hidden_4 = dense_hidden(c3_hidden)\n",
    "c4_hidden = merge([c4_dense, hidden_4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last arrow of the diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_out = Dense(vocab_size, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put in the last layer that goes out\n",
    "c5_out = dense_out(c4_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The model will have 4 inputs and 1 output\n",
    "model = Model([c1_in, c2_in, c3_in, c4_in], c5_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let a proper learning rate for the model\n",
    "model.optimizer.lr=0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# THis runs very fast so I will run lots of them\n",
    "model.fit([x1, x2, x3, x4], y, batch_size=64, nb_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Put in a steeper learning curve\n",
    "model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Run the model a few times\n",
    "model.fit([x1, x2, x3, x4], y, batch_size=64, nb_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get a detailed optimizer\n",
    "model.optimizer.lr=(0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit([x1, x2, x3, x4], y, batch_size=64, nb_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit([x1, x2, x3, x4], y, batch_size=64, nb_epoch=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a function to test the next one\n",
    "def get_next(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = [np.array(i)[np.newaxis] for i in idxs]\n",
    "    p = model.predict(arrs)\n",
    "    i = np.argmax(p)\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# book\n",
    "get_next(' boo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current = ''\n",
    "check ='k'\n",
    "chance = 0\n",
    "while (current != check):\n",
    "    model.fit([x1, x2, x3, x4], y, batch_size=64, nb_epoch=1,verbose=0)\n",
    "    current = get_next(' boo')\n",
    "    chance = chance +1\n",
    "    print (\"Run \"+str(chance) +\": Current letter is \"+current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Worship\n",
    "get_next('orsh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Goodspeed\n",
    "get_next('Good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#**ck Out\n",
    "get_next('uk O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#**ck Out\n",
    "get_next('k Ou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# **** Out ... something should go after\n",
    "get_next(' Out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pastor Manul Laphroaig\n",
    "get_next('Past')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## back to three!\n",
    "Something is very weird with 4. Lets try 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create and train model\n",
    "#Pick a size for hidden state\n",
    "\n",
    "n_hidden = 256\n",
    "cs=3\n",
    "\n",
    "#Creates the first arrow in from the model\n",
    "dense_in = Dense(n_hidden, activation='relu')\n",
    "\n",
    "# Create the hidden activation\n",
    "c1_hidden = dense_in(c1)\n",
    "\n",
    "# Orange arrows\n",
    "dense_hidden = Dense(n_hidden, activation='tanh')\n",
    "\n",
    "#The other activations\n",
    "\n",
    "c2_dense = dense_in(c2)\n",
    "hidden_2 = dense_hidden(c1_hidden)\n",
    "c2_hidden = merge([c2_dense, hidden_2])\n",
    "\n",
    "c3_dense = dense_in(c3)\n",
    "hidden_3 = dense_hidden(c2_hidden)\n",
    "c3_hidden = merge([c3_dense, hidden_3])\n",
    "\n",
    "dense_out = Dense(vocab_size, activation='softmax')\n",
    "\n",
    "# Put in the last layer that goes out\n",
    "c4_out = dense_out(c3_hidden)\n",
    "\n",
    "# The model will have 4 inputs and 1 output\n",
    "model = Model([c1_in, c2_in, c3_in], c4_out)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())\n",
    "\n",
    "# Let a proper learning rate for the model\n",
    "model.optimizer.lr=0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "266815/266815 [==============================] - 8s - loss: 2.8032     \n",
      "Epoch 2/8\n",
      "266815/266815 [==============================] - 8s - loss: 2.8597     \n",
      "Epoch 3/8\n",
      "266815/266815 [==============================] - 8s - loss: 3.2028     \n",
      "Epoch 4/8\n",
      "266815/266815 [==============================] - 8s - loss: 3.2805     \n",
      "Epoch 5/8\n",
      "266815/266815 [==============================] - 8s - loss: 3.3346     \n",
      "Epoch 6/8\n",
      "266815/266815 [==============================] - 8s - loss: 3.2611     \n",
      "Epoch 7/8\n",
      "266815/266815 [==============================] - 8s - loss: 3.2555     \n",
      "Epoch 8/8\n",
      "266815/266815 [==============================] - 8s - loss: 3.2816     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3ca18bc2e8>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr=(0.01)\n",
    "model.fit([x1, x2, x3], y, batch_size=64, nb_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "266815/266815 [==============================] - 8s - loss: 3.2745     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c682038d0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr=(0.00001)\n",
    "model.fit([x1, x2, x3], y, batch_size=64, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "266815/266815 [==============================] - 8s - loss: 3.2775     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3ca18bc470>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr=(0.01)\n",
    "model.fit([x1, x2, x3], y, batch_size=64, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "266815/266815 [==============================] - 8s - loss: 3.2781     \n",
      "Epoch 2/2\n",
      "266815/266815 [==============================] - 8s - loss: 3.2798     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3ca1a0f2e8>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr=(0.000001)\n",
    "model.fit([x1, x2, x3], y, batch_size=64, nb_epoch=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a function to test the next one\n",
    "def get_next(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = [np.array(i)[np.newaxis] for i in idxs]\n",
    "    p = model.predict(arrs)\n",
    "    i = np.argmax(p)\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Worship\n",
    "get_next('rsh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1: Current letter is d\n",
      "Run 2: Current letter is r\n",
      "Run 3: Current letter is  \n",
      "Run 4: Current letter is n\n",
      "Run 5: Current letter is  \n",
      "Run 6: Current letter is t\n",
      "Run 7: Current letter is n\n",
      "Run 8: Current letter is k\n"
     ]
    }
   ],
   "source": [
    "current = ''\n",
    "check ='k'\n",
    "chance = 0\n",
    "while (current != check):\n",
    "    model.fit([x1, x2, x3], y, batch_size=64, nb_epoch=1,verbose=0)\n",
    "    current = get_next('boo')\n",
    "    chance = chance +1\n",
    "    print (\"Run \"+str(chance) +\": Current letter is \"+current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Goodspeed\n",
    "get_next('Goo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "266815/266815 [==============================] - 8s - loss: 3.2756     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c6a2f3ba8>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x1, x2, x3], y, batch_size=64, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Time for our RNNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of the unrolled RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of letters used in the RNN\n",
    "cs=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For each of 0 through 7, create a list of every 8th character with that starting point. \n",
    "# These will be the 8 inputs to out model.\n",
    "c_in_dat = [[idx[i+n] for i in range(0, len(idx)-1-cs, cs)]\n",
    "            for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writes the outputs for the model\n",
    "c_out_dat = [idx[i+cs] for i in range(0, len(idx)-1-cs, cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gets the stack \n",
    "xs = [np.stack(c[:-2]) for c in c_in_dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, (133406,))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Breaks it into sets of 8\n",
    "len(xs), xs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.stack(c_out_dat[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([43, 75, 87,  2, 54, 71, 67, 86]),\n",
       " array([80, 81, 84, 50, 40,  2,  2, 74]),\n",
       " array([86, 80, 80, 81, 49, 18, 37,  2]),\n",
       " array([71, 67, 67, 37,  1, 90, 40, 50]),\n",
       " array([84, 78, 78,  2, 43, 18, 50, 81]),\n",
       " array([80,  2,  2, 77, 85, 18,  2, 37]),\n",
       " array([67, 44, 81,  2, 85, 14, 89,  1]),\n",
       " array([86, 81, 72, 41, 87,  2, 75, 35])]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sets up lists of characters for input\n",
    "[xs[n][:cs] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([75, 87,  2, 54, 71, 67, 86, 80])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output\n",
    "y[:cs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_input(name, n_in, n_out):\n",
    "    inp = Input(shape=(1,), dtype='int64', name=name+'_in')\n",
    "    emb = Embedding(n_in, n_out, input_length=1, name=name+'_emb')(inp)\n",
    "    return inp, Flatten()(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_ins = [embedding_input('c'+str(n), vocab_size, n_fac) for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting up the RNN model.\n",
    "# Dense in is the the first layer that shoots in\n",
    "# Dense hidden is circling around inside\n",
    "# Dense out it the exit\n",
    "dense_in = Dense(n_hidden, activation='relu')\n",
    "dense_hidden = Dense(n_hidden, activation='relu', init='identity')\n",
    "dense_out = Dense(vocab_size, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Starts our the first input as all 0s\n",
    "hidden = dense_in(c_ins[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remember CS is the number of iterations\n",
    "# This runs the loops\n",
    "for i in range(1,cs):\n",
    "    c_dense = dense_in(c_ins[i][1])\n",
    "    hidden = dense_hidden(hidden)\n",
    "    hidden = merge([c_dense, hidden])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# final stage to push it out\n",
    "c_out = dense_out(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model([c[0] for c in c_ins], c_out)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "133406/133406 [==============================] - 8s - loss: 2.7434     \n",
      "Epoch 2/12\n",
      "133406/133406 [==============================] - 8s - loss: 2.4859     \n",
      "Epoch 3/12\n",
      "133406/133406 [==============================] - 8s - loss: 2.3816     \n",
      "Epoch 4/12\n",
      "133406/133406 [==============================] - 8s - loss: 2.3075     \n",
      "Epoch 5/12\n",
      "133406/133406 [==============================] - 7s - loss: 2.2476     \n",
      "Epoch 6/12\n",
      "133406/133406 [==============================] - 7s - loss: 2.1991     \n",
      "Epoch 7/12\n",
      "133406/133406 [==============================] - 7s - loss: 2.1567     \n",
      "Epoch 8/12\n",
      "133406/133406 [==============================] - 7s - loss: 2.1215     \n",
      "Epoch 9/12\n",
      "133406/133406 [==============================] - 7s - loss: 2.0900     \n",
      "Epoch 10/12\n",
      "133406/133406 [==============================] - 7s - loss: 2.0635     \n",
      "Epoch 11/12\n",
      "133406/133406 [==============================] - 8s - loss: 2.0390     \n",
      "Epoch 12/12\n",
      "133406/133406 [==============================] - 7s - loss: 2.0172     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c695e9358>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xs, y, batch_size=64, nb_epoch=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = [np.array(char_indices[c])[np.newaxis] for c in inp]\n",
    "    p = model.predict(idxs)\n",
    "    return chars[np.argmax(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('Internat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('nternati')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('Pastor L')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN With Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The Vocab size is dependent on the file.\n",
    "n_hidden, n_fac, cs, vocab_size = (256, 42, 8, 203)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sequential model \n",
    "model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=cs),\n",
    "        SimpleRNN(n_hidden, activation='relu', inner_init='identity'),\n",
    "        Dense(vocab_size, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_10 (Embedding)         (None, 8, 42)         8526        embedding_input_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "simplernn_2 (SimpleRNN)          (None, 256)           76544       embedding_10[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_20 (Dense)                 (None, 203)           52171       simplernn_2[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 137,241\n",
      "Trainable params: 137,241\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "133406/133406 [==============================] - 10s - loss: 2.9453    \n",
      "Epoch 2/8\n",
      "133406/133406 [==============================] - 10s - loss: 2.4588    \n",
      "Epoch 3/8\n",
      "133406/133406 [==============================] - 10s - loss: 2.2626    \n",
      "Epoch 4/8\n",
      "133406/133406 [==============================] - 10s - loss: 2.1263    \n",
      "Epoch 5/8\n",
      "133406/133406 [==============================] - 10s - loss: 2.0258    \n",
      "Epoch 6/8\n",
      "133406/133406 [==============================] - 10s - loss: 1.9463    \n",
      "Epoch 7/8\n",
      "133406/133406 [==============================] - 10s - loss: 1.8833    \n",
      "Epoch 8/8\n",
      "133406/133406 [==============================] - 10s - loss: 1.8314    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c62e9fb70>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.concatenate(xs,axis=1), y, batch_size=64, nb_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nexts_keras(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arr = np.array(idxs)[np.newaxis,:]\n",
    "    p = model.predict(arr)[0]\n",
    "    print(list(inp))\n",
    "    return [chars[np.argmax(o)] for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t', 'h', 'i', 's', ' ', 'i', 's', ' ']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00',\n",
       " '\\x00']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seems off\n",
    "get_nexts_keras('this is ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_out_dat = [[idx[i+n] for i in range(1, len(idx)-cs, cs)]\n",
    "            for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ys = [np.stack(c[:-2]) for c in c_out_dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[43],\n",
       "        [75],\n",
       "        [87],\n",
       "        [ 2],\n",
       "        [54],\n",
       "        [71],\n",
       "        [67],\n",
       "        [86]]), array([[80],\n",
       "        [81],\n",
       "        [84],\n",
       "        [50],\n",
       "        [40],\n",
       "        [ 2],\n",
       "        [ 2],\n",
       "        [74]]), array([[86],\n",
       "        [80],\n",
       "        [80],\n",
       "        [81],\n",
       "        [49],\n",
       "        [18],\n",
       "        [37],\n",
       "        [ 2]]), array([[71],\n",
       "        [67],\n",
       "        [67],\n",
       "        [37],\n",
       "        [ 1],\n",
       "        [90],\n",
       "        [40],\n",
       "        [50]]), array([[84],\n",
       "        [78],\n",
       "        [78],\n",
       "        [ 2],\n",
       "        [43],\n",
       "        [18],\n",
       "        [50],\n",
       "        [81]]), array([[80],\n",
       "        [ 2],\n",
       "        [ 2],\n",
       "        [77],\n",
       "        [85],\n",
       "        [18],\n",
       "        [ 2],\n",
       "        [37]]), array([[67],\n",
       "        [44],\n",
       "        [81],\n",
       "        [ 2],\n",
       "        [85],\n",
       "        [14],\n",
       "        [89],\n",
       "        [ 1]]), array([[86],\n",
       "        [81],\n",
       "        [72],\n",
       "        [41],\n",
       "        [87],\n",
       "        [ 2],\n",
       "        [75],\n",
       "        [35]])]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[xs[n][:cs] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([80, 81, 84, 50, 40,  2,  2, 74]),\n",
       " array([86, 80, 80, 81, 49, 18, 37,  2]),\n",
       " array([71, 67, 67, 37,  1, 90, 40, 50]),\n",
       " array([84, 78, 78,  2, 43, 18, 50, 81]),\n",
       " array([80,  2,  2, 77, 85, 18,  2, 37]),\n",
       " array([67, 44, 81,  2, 85, 14, 89,  1]),\n",
       " array([86, 81, 72, 41, 87,  2, 75, 35]),\n",
       " array([75, 87,  2, 54, 71, 67, 86, 80])]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ys[n][:cs] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_in = Dense(n_hidden, activation='relu')\n",
    "dense_hidden = Dense(n_hidden, activation='relu', init='identity')\n",
    "dense_out = Dense(vocab_size, activation='softmax', name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp1 = Input(shape=(n_fac,), name='zeros')\n",
    "hidden = dense_in(inp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outs = []\n",
    "\n",
    "for i in range(cs):\n",
    "    c_dense = dense_in(c_ins[i][1])\n",
    "    hidden = dense_hidden(hidden)\n",
    "    hidden = merge([c_dense, hidden], mode='sum')\n",
    "    # every layer now has an output\n",
    "    outs.append(dense_out(hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model([inp1] + [c[0] for c in c_ins], outs)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133406, 42)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = np.tile(np.zeros(n_fac), (len(xs[0]),1))\n",
    "zeros.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "133406/133406 [==============================] - 20s - loss: 21.7578 - output_loss_1: 2.9341 - output_loss_2: 2.7872 - output_loss_3: 2.7268 - output_loss_4: 2.6858 - output_loss_5: 2.6620 - output_loss_6: 2.6616 - output_loss_7: 2.6529 - output_loss_8: 2.6473    \n",
      "Epoch 2/12\n",
      "133406/133406 [==============================] - 20s - loss: 19.8388 - output_loss_1: 2.7743 - output_loss_2: 2.6178 - output_loss_3: 2.5049 - output_loss_4: 2.4272 - output_loss_5: 2.3913 - output_loss_6: 2.3823 - output_loss_7: 2.3718 - output_loss_8: 2.3691    \n",
      "Epoch 3/12\n",
      "133406/133406 [==============================] - 20s - loss: 19.2321 - output_loss_1: 2.7590 - output_loss_2: 2.5914 - output_loss_3: 2.4473 - output_loss_4: 2.3405 - output_loss_5: 2.2899 - output_loss_6: 2.2754 - output_loss_7: 2.2647 - output_loss_8: 2.2638    \n",
      "Epoch 4/12\n",
      "133406/133406 [==============================] - 20s - loss: 18.8639 - output_loss_1: 2.7511 - output_loss_2: 2.5797 - output_loss_3: 2.4168 - output_loss_4: 2.2898 - output_loss_5: 2.2271 - output_loss_6: 2.2072 - output_loss_7: 2.1964 - output_loss_8: 2.1959    \n",
      "Epoch 5/12\n",
      "133406/133406 [==============================] - 20s - loss: 18.6119 - output_loss_1: 2.7465 - output_loss_2: 2.5724 - output_loss_3: 2.3983 - output_loss_4: 2.2565 - output_loss_5: 2.1838 - output_loss_6: 2.1602 - output_loss_7: 2.1493 - output_loss_8: 2.1448    \n",
      "Epoch 6/12\n",
      "133406/133406 [==============================] - 20s - loss: 18.4292 - output_loss_1: 2.7432 - output_loss_2: 2.5687 - output_loss_3: 2.3852 - output_loss_4: 2.2312 - output_loss_5: 2.1520 - output_loss_6: 2.1255 - output_loss_7: 2.1147 - output_loss_8: 2.1088    \n",
      "Epoch 7/12\n",
      "133406/133406 [==============================] - 21s - loss: 18.2927 - output_loss_1: 2.7417 - output_loss_2: 2.5651 - output_loss_3: 2.3762 - output_loss_4: 2.2139 - output_loss_5: 2.1289 - output_loss_6: 2.0991 - output_loss_7: 2.0864 - output_loss_8: 2.0814    \n",
      "Epoch 8/12\n",
      "133406/133406 [==============================] - 21s - loss: 18.1803 - output_loss_1: 2.7390 - output_loss_2: 2.5615 - output_loss_3: 2.3697 - output_loss_4: 2.1981 - output_loss_5: 2.1092 - output_loss_6: 2.0777 - output_loss_7: 2.0659 - output_loss_8: 2.0592    \n",
      "Epoch 9/12\n",
      "133406/133406 [==============================] - 21s - loss: 18.0932 - output_loss_1: 2.7379 - output_loss_2: 2.5602 - output_loss_3: 2.3639 - output_loss_4: 2.1867 - output_loss_5: 2.0950 - output_loss_6: 2.0611 - output_loss_7: 2.0478 - output_loss_8: 2.0405    \n",
      "Epoch 10/12\n",
      "133406/133406 [==============================] - 21s - loss: 18.0157 - output_loss_1: 2.7365 - output_loss_2: 2.5579 - output_loss_3: 2.3597 - output_loss_4: 2.1771 - output_loss_5: 2.0824 - output_loss_6: 2.0468 - output_loss_7: 2.0310 - output_loss_8: 2.0243    \n",
      "Epoch 11/12\n",
      "133406/133406 [==============================] - 21s - loss: 17.9534 - output_loss_1: 2.7361 - output_loss_2: 2.5573 - output_loss_3: 2.3546 - output_loss_4: 2.1689 - output_loss_5: 2.0710 - output_loss_6: 2.0341 - output_loss_7: 2.0191 - output_loss_8: 2.0124    \n",
      "Epoch 12/12\n",
      "133406/133406 [==============================] - 20s - loss: 17.8959 - output_loss_1: 2.7347 - output_loss_2: 2.5549 - output_loss_3: 2.3516 - output_loss_4: 2.1622 - output_loss_5: 2.0605 - output_loss_6: 2.0227 - output_loss_7: 2.0095 - output_loss_8: 1.9998    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c5d597208>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([zeros]+xs, ys, batch_size=64, nb_epoch=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nexts(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = [np.array(i)[np.newaxis] for i in idxs]\n",
    "    p = model.predict([np.zeros(n_fac)[np.newaxis,:]] + arrs)\n",
    "    print(list(inp))\n",
    "    return [chars[np.argmax(o)] for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 't', 'h', 'i', 's', ' ', 'i', 's']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', 't', ' ', 'i', 's', ' ']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts(' this is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'p', 'a', 'r', 't', ' ', 'o', 'f']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t', 'e', 'r', 'e', 'i', 'o', 'f', ' ']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts(' part of')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Model with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 42, 8, 203)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden, n_fac, cs, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=cs),\n",
    "        SimpleRNN(n_hidden, return_sequences=True, activation='relu', inner_init='identity'),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_11 (Embedding)         (None, 8, 42)         8526        embedding_input_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "simplernn_3 (SimpleRNN)          (None, 8, 256)        76544       embedding_11[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_1 (TimeDistribut (None, 8, 203)        52171       simplernn_3[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 137,241\n",
      "Trainable params: 137,241\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133406, 1)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## stack is changed to concatenate\n",
    "x_rnn=np.concatenate(xs, axis=1)\n",
    "y_rnn=np.expand_dims(np.concatenate(ys, axis=1), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((133406, 8), (133406, 8, 1))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rnn.shape, y_rnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "133406/133406 [==============================] - 12s - loss: 2.6522    \n",
      "Epoch 2/10\n",
      "133406/133406 [==============================] - 12s - loss: 2.2407    \n",
      "Epoch 3/10\n",
      "133406/133406 [==============================] - 12s - loss: 2.1205    \n",
      "Epoch 4/10\n",
      "133406/133406 [==============================] - 12s - loss: 2.0599    \n",
      "Epoch 5/10\n",
      "133406/133406 [==============================] - 12s - loss: 2.0227    \n",
      "Epoch 6/10\n",
      "133406/133406 [==============================] - 12s - loss: 1.9968    \n",
      "Epoch 7/10\n",
      "133406/133406 [==============================] - 12s - loss: 1.9769    \n",
      "Epoch 8/10\n",
      "133406/133406 [==============================] - 12s - loss: 1.9622    \n",
      "Epoch 9/10\n",
      "133406/133406 [==============================] - 12s - loss: 1.9494    \n",
      "Epoch 10/10\n",
      "133406/133406 [==============================] - 12s - loss: 1.9390    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c58b95278>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_rnn, y_rnn, batch_size=64, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nexts_keras(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arr = np.array(idxs)[np.newaxis,:]\n",
    "    p = model.predict(arr)[0]\n",
    "    print(list(inp))\n",
    "    return [chars[np.argmax(o)] for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 't', 'h', 'i', 's', ' ', 'i', 's']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', 's', ' ', 'i', 's', ' ']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_keras(' this is')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot sequence model with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "        SimpleRNN(n_hidden, return_sequences=True, input_shape=(cs, vocab_size),\n",
    "                  activation='relu', inner_init='identity'),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "    ])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((133406, 8, 203), (133406, 8, 203))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh_ys = [to_categorical(o, vocab_size) for o in ys]\n",
    "oh_y_rnn=np.stack(oh_ys, axis=1)\n",
    "\n",
    "oh_xs = [to_categorical(o, vocab_size) for o in xs]\n",
    "oh_x_rnn=np.stack(oh_xs, axis=1)\n",
    "\n",
    "oh_x_rnn.shape, oh_y_rnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "133406/133406 [==============================] - 11s - loss: 1.9549    \n",
      "Epoch 2/8\n",
      "133406/133406 [==============================] - 12s - loss: 1.9429    \n",
      "Epoch 3/8\n",
      "133406/133406 [==============================] - 12s - loss: 1.9325    \n",
      "Epoch 4/8\n",
      "133406/133406 [==============================] - 12s - loss: 1.9238    \n",
      "Epoch 5/8\n",
      "133406/133406 [==============================] - 12s - loss: 1.9160    \n",
      "Epoch 6/8\n",
      "133406/133406 [==============================] - 12s - loss: 1.9093    \n",
      "Epoch 7/8\n",
      "133406/133406 [==============================] - 12s - loss: 1.9033    \n",
      "Epoch 8/8\n",
      "133406/133406 [==============================] - 12s - loss: 1.8978    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3ab7b51ac8>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(oh_x_rnn, oh_y_rnn, batch_size=64, nb_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nexts_oh(inp):\n",
    "    idxs = np.array([char_indices[c] for c in inp])\n",
    "    arr = to_categorical(idxs, vocab_size)\n",
    "    p = model.predict(arr[np.newaxis,:])[0]\n",
    "    print(list(inp))\n",
    "    return [chars[np.argmax(o)] for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 't', 'h', 'i', 's', ' ', 'i', 's']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', 's', ' ', 'i', 's', ' ']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_oh(' this is')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stateful model with keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=cs, batch_input_shape=(bs,8)),\n",
    "        BatchNormalization(),\n",
    "        LSTM(n_hidden, return_sequences=True, stateful=True),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mx = len(x_rnn)//bs*bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "133376/133376 [==============================] - 35s - loss: nan    \n",
      "Epoch 2/4\n",
      "133376/133376 [==============================] - 35s - loss: nan    \n",
      "Epoch 3/4\n",
      "133376/133376 [==============================] - 34s - loss: nan    \n",
      "Epoch 4/4\n",
      "133376/133376 [==============================] - 34s - loss: nan    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3ab6f1bcf8>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_rnn[:mx], y_rnn[:mx], batch_size=bs, nb_epoch=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "133376/133376 [==============================] - 34s - loss: nan    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3ab6f19470>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_rnn[:mx], y_rnn[:mx], batch_size=bs, nb_epoch=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "133376/133376 [==============================] - 34s - loss: nan    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3ab6f1bf60>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_rnn[:mx], y_rnn[:mx], batch_size=bs, nb_epoch=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theano RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = vocab_size\n",
    "n_output = vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_wgts(rows, cols): \n",
    "    scale = math.sqrt(2/rows)\n",
    "    return shared(normal(scale=scale, size=(rows, cols)).astype(np.float32))\n",
    "def init_bias(rows): \n",
    "    return shared(np.zeros(rows, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wgts_and_bias(n_in, n_out): \n",
    "    return init_wgts(n_in, n_out), init_bias(n_out)\n",
    "def id_and_bias(n): \n",
    "    return shared(np.eye(n, dtype=np.float32)), init_bias(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_inp = T.matrix('inp')\n",
    "t_outp = T.matrix('outp')\n",
    "t_h0 = T.vector('h0')\n",
    "lr = T.scalar('lr')\n",
    "\n",
    "all_args = [t_h0, t_inp, t_outp, lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_h = id_and_bias(n_hidden)\n",
    "W_x = wgts_and_bias(n_input, n_hidden)\n",
    "W_y = wgts_and_bias(n_hidden, n_output)\n",
    "w_all = list(chain.from_iterable([W_h, W_x, W_y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step(x, h, W_h, b_h, W_x, b_x, W_y, b_y):\n",
    "    # Calculate the hidden activations\n",
    "    h = nnet.relu(T.dot(x, W_x) + b_x + T.dot(h, W_h) + b_h)\n",
    "    # Calculate the output activations\n",
    "    y = nnet.softmax(T.dot(h, W_y) + b_y)\n",
    "    # Return both (the 'Flatten()' is to work around a theano bug)\n",
    "    return h, T.flatten(y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[v_h, v_y], _ = theano.scan(step, sequences=t_inp, \n",
    "                            outputs_info=[t_h0, None], non_sequences=w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error = nnet.categorical_crossentropy(v_y, t_outp).sum()\n",
    "g_all = T.grad(error, w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def upd_dict(wgts, grads, lr): \n",
    "    return OrderedDict({w: w-g*lr for (w,g) in zip(wgts,grads)})\n",
    "\n",
    "upd = upd_dict(w_all, g_all, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = theano.function(all_args, error, updates=upd, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((133406, 8, 203), (133406, 8, 203))"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = oh_x_rnn\n",
    "Y = oh_y_rnn\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:27.399\n",
      "Error:23.952\n",
      "Error:21.156\n",
      "Error:22.664\n",
      "Error:21.519\n",
      "Error:21.515\n",
      "Error:20.836\n",
      "Error:20.436\n",
      "Error:21.475\n",
      "Error:20.412\n",
      "Error:20.212\n",
      "Error:19.883\n",
      "Error:19.962\n",
      "Error:19.435\n",
      "Error:22.186\n",
      "Error:20.226\n",
      "Error:19.549\n",
      "Error:20.985\n",
      "Error:18.726\n",
      "Error:17.993\n",
      "Error:19.166\n",
      "Error:17.502\n",
      "Error:21.074\n",
      "Error:19.960\n",
      "Error:16.165\n",
      "Error:17.212\n",
      "Error:17.942\n",
      "Error:19.315\n",
      "Error:19.140\n",
      "Error:18.905\n",
      "Error:18.527\n",
      "Error:17.819\n",
      "Error:17.489\n",
      "Error:16.178\n",
      "Error:17.781\n",
      "Error:16.989\n",
      "Error:17.986\n",
      "Error:17.998\n",
      "Error:17.987\n",
      "Error:17.458\n",
      "Error:17.858\n",
      "Error:17.657\n",
      "Error:17.915\n",
      "Error:18.928\n",
      "Error:18.908\n",
      "Error:18.993\n",
      "Error:16.183\n",
      "Error:17.162\n",
      "Error:18.397\n",
      "Error:21.384\n",
      "Error:18.144\n",
      "Error:16.875\n",
      "Error:19.213\n",
      "Error:17.336\n",
      "Error:17.755\n",
      "Error:17.029\n",
      "Error:17.203\n",
      "Error:16.558\n",
      "Error:17.488\n",
      "Error:17.482\n",
      "Error:17.367\n",
      "Error:17.092\n",
      "Error:17.073\n",
      "Error:18.057\n",
      "Error:16.982\n",
      "Error:16.176\n",
      "Error:16.810\n",
      "Error:17.777\n",
      "Error:18.237\n",
      "Error:17.600\n",
      "Error:16.836\n",
      "Error:17.168\n",
      "Error:19.327\n",
      "Error:18.336\n",
      "Error:17.958\n",
      "Error:17.005\n",
      "Error:15.579\n",
      "Error:17.887\n",
      "Error:16.999\n",
      "Error:16.657\n",
      "Error:17.194\n",
      "Error:16.844\n",
      "Error:15.958\n",
      "Error:16.956\n",
      "Error:18.476\n",
      "Error:19.254\n",
      "Error:16.248\n",
      "Error:14.674\n",
      "Error:17.730\n",
      "Error:18.112\n",
      "Error:17.399\n",
      "Error:19.314\n",
      "Error:18.178\n",
      "Error:17.120\n",
      "Error:18.063\n",
      "Error:17.186\n",
      "Error:16.522\n",
      "Error:17.031\n",
      "Error:17.182\n",
      "Error:17.731\n",
      "Error:18.340\n",
      "Error:16.460\n",
      "Error:16.188\n",
      "Error:18.030\n",
      "Error:17.939\n",
      "Error:16.628\n",
      "Error:17.692\n",
      "Error:17.569\n",
      "Error:17.669\n",
      "Error:18.484\n",
      "Error:19.451\n",
      "Error:16.865\n",
      "Error:19.030\n",
      "Error:17.235\n",
      "Error:17.474\n",
      "Error:16.578\n",
      "Error:16.367\n",
      "Error:16.183\n",
      "Error:16.567\n",
      "Error:16.588\n",
      "Error:16.813\n",
      "Error:17.038\n",
      "Error:15.740\n",
      "Error:15.842\n",
      "Error:17.274\n",
      "Error:17.371\n",
      "Error:15.216\n",
      "Error:16.456\n",
      "Error:18.009\n",
      "Error:17.044\n",
      "Error:17.899\n",
      "Error:18.262\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-1ec82116e4cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0ml_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0merr\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m999\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Error:{:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jd/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jd/anaconda3/lib/python3.5/site-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    987\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    988\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 989\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jd/anaconda3/lib/python3.5/site-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mp\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                                                 \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m                                                 self, node)\n\u001b[0m\u001b[1;32m    979\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "err=0.0; l_rate=0.01\n",
    "for i in range(len(X)): \n",
    "    err+=fn(np.zeros(n_hidden), X[i], Y[i], l_rate)\n",
    "    if i % 1000 == 999: \n",
    "        print (\"Error:{:.3f}\".format(err/1000))\n",
    "        err=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_y = theano.function([t_h0, t_inp], v_y, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = np.argmax(f_y(np.zeros(n_hidden), X[6]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act = np.argmax(X[6], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', ' ', 'C', 'F', 'P', ' ', 'w', 'i']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[indices_char[o] for o in act]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n', 's', ' ', ' ', ' ', 'a', 'o', 'l']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[indices_char[o] for o in pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure python RNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Just in Numpy\n",
    "def sigmoid(x): return 1/(1+np.exp(-x))\n",
    "def sigmoid_d(x): \n",
    "    output = sigmoid(x)\n",
    "    return output*(1-output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x): return np.maximum(0., x)\n",
    "def relu_d(x): return (x > 0.)*1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  0.]), array([ 1.,  0.]))"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(np.array([3.,-3.])), relu_d(np.array([3.,-3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist(a,b): return pow(a-b,2)\n",
    "def dist_d(a,b): return 2*(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eps = 1e-7\n",
    "def x_entropy(pred, actual): \n",
    "    return -np.sum(actual * np.log(np.clip(pred, eps, 1-eps)))\n",
    "def x_entropy_d(pred, actual): return -actual/pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x): return np.exp(x)/np.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax_d(x):\n",
    "    sm = softmax(x)\n",
    "    res = np.expand_dims(-sm,-1)*sm\n",
    "    res[np.diag_indices_from(res)] = sm*(1-sm)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.35667494393873245)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = np.array([0.2,0.7,0.1])\n",
    "test_actuals = np.array([0.,1.,0.])\n",
    "nnet.categorical_crossentropy(test_preds, test_actuals).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35667494393873245"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_entropy(test_preds, test_actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_inp = T.dvector()\n",
    "test_out = nnet.categorical_crossentropy(test_inp, test_actuals)\n",
    "test_grad = theano.function([test_inp], T.grad(test_out, test_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_grad(test_preds)\n",
    "\n",
    "x_entropy_d(test_preds, test_actuals)\n",
    "\n",
    "pre_pred = random(oh_x_rnn[0][0].shape)\n",
    "preds = softmax(pre_pred)\n",
    "actual = oh_x_rnn[0][0]\n",
    "\n",
    "loss=x_entropy\n",
    "loss_d=x_entropy_d\n",
    "\n",
    "np.allclose(softmax_d(pre_pred).dot(loss_d(preds,actual)), preds-actual)\n",
    "\n",
    "softmax(test_preds)\n",
    "\n",
    "nnet.softmax(test_preds).eval()\n",
    "\n",
    "test_out = T.flatten(nnet.softmax(test_inp))\n",
    "\n",
    "test_grad = theano.function([test_inp], theano.gradient.jacobian(test_out, test_inp))\n",
    "\n",
    "test_grad(test_preds)\n",
    "\n",
    "softmax_d(test_preds)\n",
    "\n",
    "act=relu\n",
    "act_d = relu_d\n",
    "\n",
    "loss=x_entropy\n",
    "loss_d=x_entropy_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scan(fn, start, seq):\n",
    "    res = []\n",
    "    prev = start\n",
    "    for s in seq:\n",
    "        app = fn(prev, s)\n",
    "        res.append(app)\n",
    "        prev = app\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 3, 6, 10]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan(lambda prev,curr: prev+curr, 0, range(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = oh_x_rnn\n",
    "outp = oh_y_rnn\n",
    "n_input = vocab_size\n",
    "n_output = vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((133406, 8, 203), (133406, 8, 203))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape, outp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_char(prev, item):\n",
    "    # Previous state\n",
    "    tot_loss, pre_hidden, pre_pred, hidden, ypred = prev\n",
    "    # Current inputs and output\n",
    "    x, y = item\n",
    "    pre_hidden = np.dot(x,w_x) + np.dot(hidden,w_h)\n",
    "    hidden = act(pre_hidden)\n",
    "    pre_pred = np.dot(hidden,w_y)\n",
    "    ypred = softmax(pre_pred)\n",
    "    return (\n",
    "        # Keep track of loss so we can report it\n",
    "        tot_loss+loss(ypred, y),\n",
    "        # Used in backprop\n",
    "        pre_hidden, pre_pred, \n",
    "        # Used in next iteration\n",
    "        hidden, \n",
    "        # To provide predictions\n",
    "        ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_chars(n): return zip(inp[n], outp[n])\n",
    "def one_fwd(n): return scan(one_char, (0,0,0,np.zeros(n_hidden),0), get_chars(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"Columnify\" a vector\n",
    "def col(x): return x[:,newaxis]\n",
    "\n",
    "def one_bkwd(args, n):\n",
    "    global w_x,w_y,w_h\n",
    "\n",
    "    i=inp[n]  # 8x86\n",
    "    o=outp[n] # 8x86\n",
    "    d_pre_hidden = np.zeros(n_hidden) # 256\n",
    "    for p in reversed(range(len(i))):\n",
    "        totloss, pre_hidden, pre_pred, hidden, ypred = args[p]\n",
    "        x=i[p] # 86\n",
    "        y=o[p] # 86\n",
    "        d_pre_pred = softmax_d(pre_pred).dot(loss_d(ypred,y))  # 86\n",
    "        d_pre_hidden = (np.dot(d_pre_hidden, w_h.T) \n",
    "                        + np.dot(d_pre_pred,w_y.T)) * act_d(pre_hidden) # 256\n",
    "\n",
    "        # d(loss)/d(w_y) = d(loss)/d(pre_pred) * d(pre_pred)/d(w_y)\n",
    "        w_y -= col(hidden) * d_pre_pred * alpha\n",
    "        # d(loss)/d(w_h) = d(loss)/d(pre_hidden[p-1]) * d(pre_hidden[p-1])/d(w_h)\n",
    "        if (p>0): w_h -= args[p-1][3].dot(d_pre_hidden) * alpha\n",
    "        w_x -= col(x)*d_pre_hidden * alpha\n",
    "    return d_pre_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale=math.sqrt(2./n_input)\n",
    "w_x = normal(scale=scale, size=(n_input,n_hidden))\n",
    "w_y = normal(scale=scale, size=(n_hidden, n_output))\n",
    "w_h = np.eye(n_hidden, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:42.5186; Gradient:2.07188\n",
      "Error:40.9153; Gradient:3.03420\n",
      "Error:37.3498; Gradient:3.70488\n",
      "Error:35.5773; Gradient:2.91971\n",
      "Error:34.2216; Gradient:3.24145\n",
      "Error:33.5074; Gradient:2.98216\n",
      "Error:32.6993; Gradient:4.16023\n",
      "Error:32.7745; Gradient:4.05214\n",
      "Error:32.9028; Gradient:2.90355\n",
      "Error:32.1005; Gradient:2.90705\n"
     ]
    }
   ],
   "source": [
    "overallError=0\n",
    "alpha=0.0001\n",
    "for n in range(10000):\n",
    "    res = one_fwd(n)\n",
    "    overallError+=res[-1][0]\n",
    "    deriv = one_bkwd(res, n)\n",
    "    if(n % 1000 == 999):\n",
    "        print (\"Error:{:.4f}; Gradient:{:.5f}\".format(\n",
    "                overallError/1000, np.linalg.norm(deriv)))\n",
    "        overallError=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "        GRU(n_hidden, return_sequences=True, input_shape=(cs, vocab_size),\n",
    "                  activation='relu', inner_init='identity'),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "    ])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "133406/133406 [==============================] - 22s - loss: 2.5788    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a9b36e748>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(oh_x_rnn, oh_y_rnn, batch_size=64, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 't', 'h', 'i', 's', ' ', 'i', 's']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', 's', ' ', 'i', 'n', ' ']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_oh(' this is')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theano GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_h = id_and_bias(n_hidden)\n",
    "W_x = init_wgts(n_input, n_hidden)\n",
    "W_y = wgts_and_bias(n_hidden, n_output)\n",
    "rW_h = init_wgts(n_hidden, n_hidden)\n",
    "rW_x = wgts_and_bias(n_input, n_hidden)\n",
    "uW_h = init_wgts(n_hidden, n_hidden)\n",
    "uW_x = wgts_and_bias(n_input, n_hidden)\n",
    "w_all = list(chain.from_iterable([W_h, W_y, uW_x, rW_x]))\n",
    "w_all.extend([W_x, uW_h, rW_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gate(x, h, W_h, W_x, b_x):\n",
    "    return nnet.sigmoid(T.dot(x, W_x) + b_x + T.dot(h, W_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step(x, h, W_h, b_h, W_y, b_y, uW_x, ub_x, rW_x, rb_x, W_x, uW_h, rW_h):\n",
    "    reset = gate(x, h, rW_h, rW_x, rb_x)\n",
    "    update = gate(x, h, uW_h, uW_x, ub_x)\n",
    "    h_new = gate(x, h * reset, W_h, W_x, b_h)\n",
    "    h = update*h + (1-update)*h_new\n",
    "    y = nnet.softmax(T.dot(h, W_y) + b_y)\n",
    "    return h, T.flatten(y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[v_h, v_y], _ = theano.scan(step, sequences=t_inp, \n",
    "                            outputs_info=[t_h0, None], non_sequences=w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error = nnet.categorical_crossentropy(v_y, t_outp).sum()\n",
    "g_all = T.grad(error, w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "upd = upd_dict(w_all, g_all, lr)\n",
    "fn = theano.function(all_args, error, updates=upd, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:28.15\n",
      "Error:23.78\n",
      "Error:21.15\n",
      "Error:23.13\n",
      "Error:22.09\n",
      "Error:22.14\n",
      "Error:21.46\n",
      "Error:21.20\n",
      "Error:22.24\n",
      "Error:21.32\n",
      "Error:20.93\n",
      "Error:20.70\n",
      "Error:20.92\n",
      "Error:20.31\n",
      "Error:22.89\n",
      "Error:21.13\n",
      "Error:20.69\n",
      "Error:21.75\n",
      "Error:19.52\n",
      "Error:19.13\n",
      "Error:20.27\n",
      "Error:18.51\n",
      "Error:22.33\n",
      "Error:21.16\n",
      "Error:17.59\n",
      "Error:20.25\n",
      "Error:19.27\n",
      "Error:20.77\n",
      "Error:20.46\n",
      "Error:20.27\n",
      "Error:19.46\n",
      "Error:19.38\n",
      "Error:18.94\n",
      "Error:17.74\n",
      "Error:19.40\n",
      "Error:19.01\n",
      "Error:19.60\n",
      "Error:19.68\n",
      "Error:19.24\n",
      "Error:18.71\n",
      "Error:19.29\n",
      "Error:19.24\n",
      "Error:19.78\n",
      "Error:20.42\n",
      "Error:21.25\n",
      "Error:21.73\n",
      "Error:18.09\n",
      "Error:18.90\n",
      "Error:20.58\n",
      "Error:24.54\n",
      "Error:20.15\n",
      "Error:18.64\n",
      "Error:20.53\n",
      "Error:18.74\n",
      "Error:19.22\n",
      "Error:19.01\n",
      "Error:19.40\n",
      "Error:18.92\n",
      "Error:19.18\n",
      "Error:19.21\n",
      "Error:19.66\n",
      "Error:18.91\n",
      "Error:20.97\n",
      "Error:20.57\n",
      "Error:20.35\n",
      "Error:18.41\n",
      "Error:19.49\n",
      "Error:20.57\n",
      "Error:20.80\n",
      "Error:19.12\n",
      "Error:18.86\n",
      "Error:18.96\n",
      "Error:20.84\n",
      "Error:20.76\n",
      "Error:20.02\n",
      "Error:19.59\n",
      "Error:20.18\n",
      "Error:20.85\n",
      "Error:19.77\n",
      "Error:19.48\n",
      "Error:20.33\n",
      "Error:19.74\n",
      "Error:18.91\n",
      "Error:19.38\n",
      "Error:21.10\n",
      "Error:23.49\n",
      "Error:19.90\n",
      "Error:17.45\n",
      "Error:21.08\n",
      "Error:20.19\n",
      "Error:18.97\n",
      "Error:21.42\n",
      "Error:19.93\n",
      "Error:19.41\n",
      "Error:20.49\n",
      "Error:19.57\n",
      "Error:19.75\n",
      "Error:19.70\n",
      "Error:19.87\n",
      "Error:21.21\n",
      "Error:24.49\n",
      "Error:21.95\n",
      "Error:20.13\n",
      "Error:21.61\n",
      "Error:22.26\n",
      "Error:21.76\n",
      "Error:22.19\n",
      "Error:20.61\n",
      "Error:20.45\n",
      "Error:22.59\n",
      "Error:22.14\n",
      "Error:19.69\n",
      "Error:21.30\n",
      "Error:19.28\n",
      "Error:20.33\n",
      "Error:19.55\n",
      "Error:19.49\n",
      "Error:19.83\n",
      "Error:19.99\n",
      "Error:19.57\n",
      "Error:23.64\n",
      "Error:23.53\n",
      "Error:20.90\n",
      "Error:20.10\n",
      "Error:21.63\n",
      "Error:23.11\n",
      "Error:21.48\n",
      "Error:21.08\n",
      "Error:21.18\n",
      "Error:20.32\n",
      "Error:22.78\n",
      "Error:21.29\n",
      "Error:20.15\n"
     ]
    }
   ],
   "source": [
    "err=0.0; l_rate=0.1\n",
    "for i in range(len(X)): \n",
    "    err+=fn(np.zeros(n_hidden), X[i], Y[i], l_rate)\n",
    "    if i % 1000 == 999: \n",
    "        l_rate *= 0.95\n",
    "        print (\"Error:{:.2f}\".format(err/1000))\n",
    "        err=0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = (shared(np.concatenate([np.eye(n_hidden), normal(size=(n_input, n_hidden))])\n",
    "            .astype(np.float32)), init_bias(n_hidden))\n",
    "\n",
    "rW = wgts_and_bias(n_input+n_hidden, n_hidden)\n",
    "uW = wgts_and_bias(n_input+n_hidden, n_hidden)\n",
    "W_y = wgts_and_bias(n_hidden, n_output)\n",
    "w_all = list(chain.from_iterable([W, W_y, uW, rW]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gate(m, W, b): return nnet.sigmoid(T.dot(m, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step(x, h, W, b, W_y, b_y, uW, ub, rW, rb):\n",
    "    m = T.concatenate([h, x])\n",
    "    reset = gate(m, rW, rb)\n",
    "    update = gate(m, uW, ub)\n",
    "    m = T.concatenate([h*reset, x])\n",
    "    h_new = gate(m, W, b)\n",
    "    h = update*h + (1-update)*h_new\n",
    "    y = nnet.softmax(T.dot(h, W_y) + b_y)\n",
    "    return h, T.flatten(y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[v_h, v_y], _ = theano.scan(step, sequences=t_inp, \n",
    "                            outputs_info=[t_h0, None], non_sequences=w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def upd_dict(wgts, grads, lr): \n",
    "    return OrderedDict({w: w-g*lr for (w,g) in zip(wgts,grads)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error = nnet.categorical_crossentropy(v_y, t_outp).sum()\n",
    "g_all = T.grad(error, w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "upd = upd_dict(w_all, g_all, lr)\n",
    "fn = theano.function(all_args, error, updates=upd, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:18.62\n",
      "Error:19.07\n",
      "Error:19.82\n",
      "Error:17.84\n",
      "Error:17.68\n",
      "Error:18.15\n",
      "Error:17.63\n",
      "Error:17.93\n",
      "Error:18.99\n",
      "Error:18.03\n",
      "Error:18.02\n",
      "Error:18.33\n",
      "Error:18.18\n",
      "Error:17.57\n",
      "Error:21.23\n",
      "Error:18.59\n",
      "Error:19.59\n",
      "Error:19.22\n",
      "Error:17.37\n",
      "Error:17.35\n",
      "Error:18.27\n",
      "Error:17.07\n",
      "Error:20.19\n",
      "Error:19.58\n",
      "Error:16.57\n",
      "Error:19.53\n",
      "Error:18.42\n",
      "Error:18.73\n",
      "Error:18.32\n",
      "Error:17.97\n",
      "Error:17.77\n",
      "Error:17.92\n",
      "Error:17.40\n",
      "Error:16.10\n",
      "Error:17.87\n",
      "Error:17.08\n",
      "Error:17.88\n",
      "Error:17.93\n",
      "Error:17.64\n",
      "Error:17.32\n",
      "Error:17.62\n",
      "Error:17.59\n",
      "Error:17.54\n",
      "Error:18.87\n",
      "Error:19.30\n",
      "Error:19.86\n",
      "Error:16.47\n",
      "Error:16.99\n",
      "Error:19.12\n",
      "Error:24.49\n",
      "Error:18.20\n",
      "Error:16.89\n",
      "Error:18.72\n",
      "Error:17.25\n",
      "Error:17.55\n",
      "Error:17.28\n",
      "Error:17.74\n",
      "Error:17.07\n",
      "Error:17.83\n",
      "Error:17.60\n",
      "Error:17.96\n",
      "Error:17.32\n",
      "Error:17.62\n",
      "Error:18.32\n",
      "Error:18.21\n",
      "Error:16.49\n",
      "Error:17.36\n",
      "Error:18.50\n",
      "Error:19.20\n",
      "Error:17.56\n",
      "Error:17.40\n",
      "Error:17.43\n",
      "Error:19.25\n",
      "Error:18.80\n",
      "Error:18.55\n",
      "Error:17.20\n",
      "Error:16.81\n",
      "Error:18.52\n",
      "Error:17.32\n",
      "Error:16.96\n",
      "Error:17.63\n",
      "Error:17.26\n",
      "Error:16.48\n",
      "Error:17.38\n",
      "Error:19.05\n",
      "Error:21.18\n",
      "Error:17.74\n",
      "Error:15.63\n",
      "Error:19.16\n",
      "Error:18.46\n",
      "Error:17.70\n",
      "Error:19.59\n",
      "Error:18.27\n",
      "Error:17.44\n",
      "Error:18.33\n",
      "Error:17.44\n",
      "Error:17.33\n",
      "Error:17.43\n",
      "Error:17.87\n",
      "Error:17.93\n",
      "Error:19.97\n",
      "Error:17.83\n",
      "Error:17.08\n",
      "Error:18.21\n",
      "Error:18.86\n",
      "Error:17.80\n",
      "Error:18.82\n",
      "Error:17.83\n",
      "Error:18.15\n",
      "Error:19.50\n",
      "Error:19.78\n",
      "Error:17.49\n",
      "Error:19.35\n",
      "Error:17.57\n",
      "Error:18.14\n",
      "Error:17.36\n",
      "Error:17.24\n",
      "Error:17.37\n",
      "Error:17.42\n",
      "Error:17.50\n",
      "Error:18.84\n",
      "Error:19.12\n",
      "Error:17.32\n",
      "Error:16.82\n",
      "Error:18.09\n",
      "Error:19.13\n",
      "Error:17.27\n",
      "Error:17.71\n",
      "Error:18.50\n",
      "Error:17.87\n",
      "Error:19.58\n",
      "Error:19.01\n",
      "Error:17.78\n"
     ]
    }
   ],
   "source": [
    "err=0.0; l_rate=0.001\n",
    "for i in range(len(X)): \n",
    "    err+=fn(np.zeros(n_hidden), X[i], Y[i], l_rate)\n",
    "    if i % 1000 == 999: \n",
    "        print (\"Error:{:.2f}\".format(err/1000))\n",
    "        err=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
